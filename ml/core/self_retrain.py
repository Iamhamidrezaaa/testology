#!/usr/bin/env python3
"""
Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„ Testology
Ø§ÛŒÙ† Ø§Ø³Ú©Ø±ÛŒÙ¾Øª Ø¨Ù‡ ØµÙˆØ±Øª Ø®ÙˆØ¯Ú©Ø§Ø± Ù…Ø¯Ù„ Ø±Ø§ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ù…ÛŒâ€ŒÚ©Ù†Ø¯
"""

import pandas as pd
import joblib
import json
import os
import sys
from datetime import datetime
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

# Ø§Ø¶Ø§ÙÙ‡ Ú©Ø±Ø¯Ù† Ù…Ø³ÛŒØ± utils
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

MODEL_PATH = "ml/core/model.pkl"
LOG_PATH = "ml/data/retrain_log.json"
BACKUP_PATH = "ml/core/model_backup.pkl"

def load_existing_data():
    """Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù…ÙˆØ¬ÙˆØ¯ Ø§Ø² Ø¯ÛŒØªØ§Ø¨ÛŒØ³"""
    try:
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ³Øªâ€ŒÙ‡Ø§
        if os.path.exists("ml/data/user_tests.csv"):
            df = pd.read_csv("ml/data/user_tests.csv")
        else:
            # Ø§Ú¯Ø± ÙØ§ÛŒÙ„ ÙˆØ¬ÙˆØ¯ Ù†Ø¯Ø§Ø´ØªØŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø³Ø§Ø²
            return create_sample_data()
        
        # Ø®ÙˆØ§Ù†Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ú†Øª Ùˆ ØªØ¹Ø§Ù…Ù„Ø§Øª
        chat_data = []
        if os.path.exists("ml/data/chat_sentiments.json"):
            with open("ml/data/chat_sentiments.json", 'r', encoding='utf-8') as f:
                chat_data = json.load(f)
        
        return df, chat_data
    except Exception as e:
        print(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
        return create_sample_data()

def create_sample_data():
    """Ø§ÛŒØ¬Ø§Ø¯ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ³Øª"""
    import numpy as np
    
    np.random.seed(42)
    n_samples = 500
    
    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    data = {
        'score': np.random.normal(50, 15, n_samples),
        'gender': np.random.choice(['male', 'female', 'other'], n_samples),
        'age': np.random.randint(18, 65, n_samples),
        'category': np.random.choice(['anxiety', 'depression', 'focus', 'confidence', 'stress'], n_samples)
    }
    
    df = pd.DataFrame(data)
    df.to_csv("ml/data/user_tests.csv", index=False)
    
    return df, []

def preprocess_data_for_retrain(df):
    """Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ"""
    # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù† Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
    df = df.dropna()
    df = df[df['score'].between(0, 100)]  # Ù†Ù…Ø±Ø§Øª Ù…Ø¹ØªØ¨Ø±
    df = df[df['age'].between(18, 100)]   # Ø³Ù† Ù…Ø¹ØªØ¨Ø±
    
    # Ú©Ø¯Ú¯Ø°Ø§Ø±ÛŒ Ù…ØªØºÛŒØ±Ù‡Ø§ÛŒ Ú©ÛŒÙÛŒ
    le = LabelEncoder()
    df["gender_encoded"] = le.fit_transform(df["gender"].astype(str))
    
    # Ù†Ø±Ù…Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Ù†Ù…Ø±Ø§Øª
    scaler = MinMaxScaler()
    df["score_scaled"] = scaler.fit_transform(df[["score"]])
    
    # Ø§Ù†ØªØ®Ø§Ø¨ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
    features = df[["score_scaled", "gender_encoded", "age"]]
    labels = df["category"]
    
    return features, labels, le, scaler

def backup_existing_model():
    """Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ù…ÙˆØ¬ÙˆØ¯"""
    if os.path.exists(MODEL_PATH):
        import shutil
        shutil.copy2(MODEL_PATH, BACKUP_PATH)
        return True
    return False

def retrain_model():
    """Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ù…Ø¯Ù„ Ø¨Ø§ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ø¯ÛŒØ¯"""
    try:
        print("ğŸ”„ Ø´Ø±ÙˆØ¹ ÙØ±Ø¢ÛŒÙ†Ø¯ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯...")
        
        # Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        df, chat_data = load_existing_data()
        print(f"ğŸ“Š Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ {len(df)} Ù†Ù…ÙˆÙ†Ù‡ Ø¯Ø§Ø¯Ù‡")
        
        # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´
        X, y, le, scaler = preprocess_data_for_retrain(df)
        print(f"âœ… Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ú©Ø§Ù…Ù„: {X.shape[0]} Ù†Ù…ÙˆÙ†Ù‡ØŒ {X.shape[1]} ÙˆÛŒÚ˜Ú¯ÛŒ")
        
        # ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )
        
        # Ù¾Ø´ØªÛŒØ¨Ø§Ù†â€ŒÚ¯ÛŒØ±ÛŒ Ø§Ø² Ù…Ø¯Ù„ Ù‚Ø¨Ù„ÛŒ
        backup_success = backup_existing_model()
        
        # Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯
        print("ğŸ§  Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„ Ø¬Ø¯ÛŒØ¯...")
        model = RandomForestClassifier(
            n_estimators=250,
            max_depth=12,
            random_state=42,
            class_weight='balanced',
            n_jobs=-1
        )
        
        model.fit(X_train, y_train)
        
        # Ø§Ø±Ø²ÛŒØ§Ø¨ÛŒ Ù…Ø¯Ù„
        y_pred = model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù…Ø¯Ù„ Ùˆ preprocessors
        os.makedirs("ml/core", exist_ok=True)
        joblib.dump(model, MODEL_PATH)
        joblib.dump(le, "ml/core/label_encoder.pkl")
        joblib.dump(scaler, "ml/core/scaler.pkl")
        
        # Ú¯Ø²Ø§Ø±Ø´ ØªÙØµÛŒÙ„ÛŒ
        report = classification_report(y_test, y_pred, output_dict=True)
        
        # Ø«Ø¨Øª Ø¯Ø± Ù„Ø§Ú¯
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "samples": len(X),
            "training_samples": len(X_train),
            "test_samples": len(X_test),
            "accuracy": round(accuracy, 4),
            "model_params": {
                "n_estimators": 250,
                "max_depth": 12,
                "features": list(X.columns)
            },
            "backup_created": backup_success,
            "categories": list(y.unique()),
            "classification_report": report
        }
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯
        if os.path.exists(LOG_PATH):
            with open(LOG_PATH, 'r', encoding='utf-8') as f:
                history = json.load(f)
        else:
            history = []
        
        history.append(log_entry)
        
        # Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ† ÙÙ‚Ø· 50 ÙˆØ±ÙˆØ¯ÛŒ Ø¢Ø®Ø±
        if len(history) > 50:
            history = history[-50:]
        
        with open(LOG_PATH, 'w', encoding='utf-8') as f:
            json.dump(history, f, ensure_ascii=False, indent=2)
        
        # Ù†ØªÛŒØ¬Ù‡ Ù†Ù‡Ø§ÛŒÛŒ
        result = {
            "status": "success",
            "message": "Ù…Ø¯Ù„ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø¨Ø§Ø²Ø¢Ù…ÙˆØ²ÛŒ Ø´Ø¯",
            "accuracy": round(accuracy, 4),
            "samples": len(X),
            "training_samples": len(X_train),
            "test_samples": len(X_test),
            "backup_created": backup_success,
            "categories": list(y.unique()),
            "timestamp": datetime.now().isoformat()
        }
        
        print("âœ… Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯")
        print(f"ğŸ“ˆ Ø¯Ù‚Øª Ù…Ø¯Ù„: {accuracy:.4f}")
        print(f"ğŸ“Š ØªØ¹Ø¯Ø§Ø¯ Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§: {len(X)}")
        
        return result
        
    except Exception as e:
        error_result = {
            "status": "error",
            "message": f"Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }
        print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¬Ø¯Ø¯: {e}")
        return error_result

def main():
    """ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ"""
    print("ğŸš€ Ø´Ø±ÙˆØ¹ Ø³ÛŒØ³ØªÙ… Ø¢Ù…ÙˆØ²Ø´ Ø®ÙˆØ¯Ú©Ø§Ø± Testology")
    print("=" * 50)
    
    result = retrain_model()
    
    # Ø®Ø±ÙˆØ¬ÛŒ JSON Ø¨Ø±Ø§ÛŒ API
    print(json.dumps(result, ensure_ascii=False))

if __name__ == "__main__":
    main()













